# ChangeLens Experiment Results Summary

**Generated**: 2026-01-16 11:04:14  
**Experiment Runs**: 3 per scenario

---

## Methodology

### Experimental Design

We conducted a comparative evaluation of Blue-Green and Canary deployment strategies using the ChangeLens benchmark. Each scenario was executed **3 times** with different random seeds (base seed: 42, seeds: 42-44) to ensure statistical validity.

### System Configuration

- **Microservices**: API v1 (baseline), API v2 (with regressions), Downstream service
- **Database**: PostgreSQL 15
- **Load Generator**: k6 with 10 concurrent virtual users
- **Test Duration**: 10 minutes per run (60s warmup + 540s main test)
- **Regression Types**: CPU contention, missing DB index, downstream latency/errors
- **Rollback Thresholds**: P99 latency > 500ms OR error rate > 5% for 2 consecutive windows

### Deployment Schedules

**Blue-Green Deployment**:
- T=120s: Instant 100% traffic switch from v1 to v2

**Canary Deployment**:
- T=120s: 5% traffic to v2
- T=180s: 25% traffic to v2  
- T=240s: 100% traffic to v2

### Statistical Analysis

- **Confidence Intervals**: 95% bootstrap confidence intervals (percentile method, 1000 bootstrap samples)
- **Effect Size**: Cliff's Delta for non-parametric comparison
- **Metrics**: Mean ± standard deviation with 95% CI

---

## Results

### Performance Metrics

#### P99 Latency

| Scenario | Mean ± SD (ms) | 95% CI (ms) |
|----------|----------------|-------------|
| **Canary** | 446.13 ± 23.38 | [424.05, 470.63] |
| **Blue-Green** | 429.52 ± 14.18 | [419.87, 445.80] |

#### Error Rate

| Scenario | Mean ± SD (%) | 95% CI (%) |
|----------|---------------|------------|
| **Canary** | 0.02 ± 0.02 | [0.00, 0.04] |
| **Blue-Green** | 0.06 ± 0.01 | [0.05, 0.07] |

#### Impact Scope (Canary)

- **Traffic to v2 before rollback**: 0.00% [0.00, 0.00]
- **Affected users**: 0.00% [0.00, 0.00]

### Effect Size Comparison

- **p99_latency**: Cohen's d = -0.859 (large effect)
- **error_rate**: Cohen's d = 2.353 (large effect)

---

## Key Findings

1. **Deployment Strategy Comparison**: Canary deployment shows [describe findings based on results]

2. **Time-to-Detection**: [Describe TTD findings]

3. **Recovery Characteristics**: [Describe recovery time findings]

4. **Impact Mitigation**: Canary deployment limits impact to [X]% of traffic before rollback, compared to 100% for Blue-Green.

---

## Threats to Validity

1. **External Validity**: Results are based on a synthetic microservice benchmark. Real-world systems may exhibit different characteristics due to network conditions, hardware variations, and application-specific behaviors.

2. **Internal Validity**: The controlled regression scenarios (CPU, DB, downstream) may not capture all types of performance regressions encountered in production systems.

3. **Measurement Validity**: Metrics are collected using 10-second aggregation windows. Finer-grained analysis might reveal additional patterns, but coarser windows might miss rapid changes.

---

## Reproducibility

All experiments were conducted with:
- Fixed random seeds (42-51) for deterministic behavior
- Docker containerization for consistent environments
- Complete configuration capture (git commit, docker images, environment variables)
- Configuration files saved in `results/run_*/config.json`

To reproduce these results:
1. Ensure Docker services are running: `docker compose up -d`
2. Run experiment suite: `python scripts/run_experiment_suite.py --scenario canary --n-runs 10`
3. Aggregate results: `python scripts/statistical_analysis.py --runs-dir results/canary --scenario canary --output aggregated.json`

---

*Generated by ChangeLens Research Infrastructure*
