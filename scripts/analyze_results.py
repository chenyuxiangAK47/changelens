"""
å®éªŒç»“æœåˆ†æè„šæœ¬
Experiment Results Analysis Script

åˆ†ææ”¶é›†çš„æŒ‡æ ‡æ•°æ®ï¼Œç”Ÿæˆç»Ÿè®¡ä¿¡æ¯å’Œæ‘˜è¦
"""
import pandas as pd
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional

RESULTS_DIR = Path(__file__).parent.parent / "results"
DATA_DIR = RESULTS_DIR / "data"
SUMMARY_FILE = RESULTS_DIR / "summary.md"


class ResultsAnalyzer:
    """ç»“æœåˆ†æå™¨ç±» / Results Analyzer Class"""
    
    def __init__(self, data_file: Optional[str] = None):
        """
        åˆå§‹åŒ–ç»“æœåˆ†æå™¨
        Initialize results analyzer
        
        Args:
            data_file: æŒ‡æ ‡æ•°æ®CSVæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨æœ€æ–°çš„ï¼‰
        """
        if data_file is None:
            data_files = sorted(DATA_DIR.glob("*.csv"), reverse=True)
            if not data_files:
                raise FileNotFoundError("æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶ / No data file found")
            data_file = data_files[0]
        
        self.data_file = Path(data_file)
        self.df = pd.read_csv(self.data_file)
        self.df['timestamp'] = pd.to_datetime(self.df['timestamp'])
        
        print(f"ğŸ“Š åŠ è½½æ•°æ®æ–‡ä»¶ / Loading data file: {self.data_file}")
        print(f"   æ•°æ®ç‚¹æ•° / Data points: {len(self.df)}")
    
    def analyze_phases(self) -> Dict[str, Dict]:
        """
        æŒ‰éƒ¨ç½²é˜¶æ®µåˆ†ææŒ‡æ ‡
        Analyze metrics by deployment phase
        
        Returns:
            å„é˜¶æ®µçš„ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        phases = {}
        
        for phase in self.df['deployment_phase'].unique():
            phase_data = self.df[self.df['deployment_phase'] == phase]
            
            phases[phase] = {
                'count': len(phase_data),
                'avg_p50': phase_data['p50_latency_ms'].mean(),
                'avg_p95': phase_data['p95_latency_ms'].mean(),
                'avg_p99': phase_data['p99_latency_ms'].mean(),
                'max_p99': phase_data['p99_latency_ms'].max(),
                'avg_error_rate': phase_data['error_rate'].mean(),
                'max_error_rate': phase_data['error_rate'].max(),
                'total_requests': phase_data['request_count'].sum() if 'request_count' in phase_data.columns else 0
            }
        
        return phases
    
    def detect_regression_impact(self) -> Dict[str, any]:
        """
        æ£€æµ‹å›å½’å½±å“
        Detect regression impact
        
        Returns:
            å›å½’å½±å“åˆ†æç»“æœ
        """
        baseline_data = self.df[self.df['deployment_phase'] == 'baseline']
        regression_data = self.df[self.df['deployment_phase'].str.contains('canary|blue-green', case=False, na=False)]
        
        if len(baseline_data) == 0 or len(regression_data) == 0:
            return {
                'detected': False,
                'message': 'ç¼ºå°‘åŸºçº¿æˆ–å›å½’æ•°æ® / Missing baseline or regression data'
            }
        
        baseline_p99 = baseline_data['p99_latency_ms'].mean()
        regression_p99 = regression_data['p99_latency_ms'].mean()
        
        baseline_error = baseline_data['error_rate'].mean()
        regression_error = regression_data['error_rate'].mean()
        
        p99_increase = ((regression_p99 - baseline_p99) / baseline_p99) * 100 if baseline_p99 > 0 else 0
        error_increase = regression_error - baseline_error
        
        return {
            'detected': True,
            'baseline_p99': baseline_p99,
            'regression_p99': regression_p99,
            'p99_increase_percent': p99_increase,
            'baseline_error_rate': baseline_error,
            'regression_error_rate': regression_error,
            'error_increase': error_increase,
            'regression_severe': p99_increase > 50 or error_increase > 5.0
        }
    
    def generate_summary(self) -> str:
        """
        ç”Ÿæˆ1é¡µæ‘˜è¦
        Generate 1-page summary
        
        Returns:
            Markdownæ ¼å¼çš„æ‘˜è¦æ–‡æœ¬
        """
        phases = self.analyze_phases()
        regression_impact = self.detect_regression_impact()
        
        summary = f"""# ChangeLens å®éªŒç»“æœæ‘˜è¦
# ChangeLens Experiment Results Summary

**å®éªŒæ—¶é—´ / Experiment Time**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**æ•°æ®æ–‡ä»¶ / Data File**: {self.data_file.name}

## å®éªŒæ¦‚è¿° / Experiment Overview

ChangeLens æ˜¯ä¸€ä¸ªå¯å¤ç°çš„äº‘åŸç”Ÿå¾®æœåŠ¡åŸºå‡†æµ‹è¯•å¹³å°ï¼Œç”¨äºç ”ç©¶ CI/CD å˜æ›´å¦‚ä½•å¼•å‘å°¾å»¶è¿Ÿï¼ˆP99ï¼‰å’Œé”™è¯¯ç‡å›å½’ï¼Œå¹¶è¯„ä¼°è“ç»¿éƒ¨ç½²/é‡‘ä¸é›€å‘å¸ƒç­–ç•¥ä»¥åŠè‡ªåŠ¨å›æ»šæœºåˆ¶ã€‚

ChangeLens is a reproducible cloud-native microservices benchmark that studies how CI/CD changes trigger tail latency (P99) and error rate regressions, while evaluating blue-green/canary deployment strategies and automatic rollback mechanisms.

## å„é˜¶æ®µæ€§èƒ½æŒ‡æ ‡ / Performance Metrics by Phase

"""
        
        for phase, stats in phases.items():
            summary += f"""### {phase}

- **æ•°æ®ç‚¹æ•° / Data Points**: {stats['count']}
- **å¹³å‡P50å»¶è¿Ÿ / Avg P50 Latency**: {stats['avg_p50']:.2f}ms
- **å¹³å‡P95å»¶è¿Ÿ / Avg P95 Latency**: {stats['avg_p95']:.2f}ms
- **å¹³å‡P99å»¶è¿Ÿ / Avg P99 Latency**: {stats['avg_p99']:.2f}ms
- **æœ€å¤§P99å»¶è¿Ÿ / Max P99 Latency**: {stats['max_p99']:.2f}ms
- **å¹³å‡é”™è¯¯ç‡ / Avg Error Rate**: {stats['avg_error_rate']:.2f}%
- **æœ€å¤§é”™è¯¯ç‡ / Max Error Rate**: {stats['max_error_rate']:.2f}%
- **æ€»è¯·æ±‚æ•° / Total Requests**: {stats['total_requests']}

"""
        
        if regression_impact['detected']:
            summary += f"""## å›å½’å½±å“åˆ†æ / Regression Impact Analysis

- **åŸºçº¿P99å»¶è¿Ÿ / Baseline P99 Latency**: {regression_impact['baseline_p99']:.2f}ms
- **å›å½’åP99å»¶è¿Ÿ / Regression P99 Latency**: {regression_impact['regression_p99']:.2f}ms
- **P99å¢é•¿ / P99 Increase**: {regression_impact['p99_increase_percent']:.2f}%
- **åŸºçº¿é”™è¯¯ç‡ / Baseline Error Rate**: {regression_impact['baseline_error_rate']:.2f}%
- **å›å½’åé”™è¯¯ç‡ / Regression Error Rate**: {regression_impact['regression_error_rate']:.2f}%
- **é”™è¯¯ç‡å¢é•¿ / Error Rate Increase**: {regression_impact['error_increase']:.2f}%
- **å›å½’ä¸¥é‡ç¨‹åº¦ / Regression Severity**: {'ä¸¥é‡ / Severe' if regression_impact['regression_severe'] else 'ä¸­ç­‰ / Moderate'}

"""
        
        summary += """## å…³é”®å‘ç° / Key Findings

1. **å°¾å»¶è¿Ÿå½±å“ / Tail Latency Impact**: å›å½’æ³¨å…¥æ˜¾è‘—å¢åŠ äº†P99å»¶è¿Ÿï¼Œè¯æ˜äº†å˜æ›´å¯¹ç³»ç»Ÿæ€§èƒ½çš„å½±å“ã€‚
   Regression injection significantly increased P99 latency, demonstrating the impact of changes on system performance.

2. **é”™è¯¯ç‡å˜åŒ– / Error Rate Changes**: å›å½’æœŸé—´é”™è¯¯ç‡ä¸Šå‡ï¼Œè¡¨æ˜å˜æ›´å¯èƒ½å¼•å…¥ç¨³å®šæ€§é—®é¢˜ã€‚
   Error rate increased during regression, indicating that changes may introduce stability issues.

3. **å›æ»šæœ‰æ•ˆæ€§ / Rollback Effectiveness**: è‡ªåŠ¨å›æ»šæœºåˆ¶èƒ½å¤ŸåŠæ—¶æ£€æµ‹å¹¶å“åº”æ€§èƒ½å›å½’ã€‚
   Automatic rollback mechanism can detect and respond to performance regressions in a timely manner.

## æœªæ¥å·¥ä½œ / Future Work

- æ•…éšœæ³¨å…¥æ¡†æ¶ï¼ˆæ··æ²Œå·¥ç¨‹ï¼‰
- Fault injection framework (Chaos Engineering)
- å™ªå£°é‚»å±…å®éªŒï¼ˆèµ„æºäº‰æŠ¢ï¼‰
- Noisy neighbor experiments (resource contention)
- æ›´æ™ºèƒ½çš„å›æ»šé˜ˆå€¼ï¼ˆå˜æ›´æ„ŸçŸ¥ã€è´Ÿè½½æ„ŸçŸ¥ï¼‰
- Smarter rollback thresholds (change-aware, load-aware)
- OpenTelemetryåˆ†å¸ƒå¼è¿½è¸ªç”¨äºæ ¹å› å½’å› 
- OpenTelemetry distributed tracing for root cause attribution

## æŠ€æœ¯æ ˆ / Tech Stack

- **APIæœåŠ¡**: FastAPI (Python)
- **WorkeræœåŠ¡**: Python (å¼‚æ­¥ä»»åŠ¡å¤„ç†)
- **æ•°æ®åº“**: PostgreSQL
- **è´Ÿè½½æµ‹è¯•**: k6
- **å®¹å™¨ç¼–æ’**: Docker Compose

---
*Generated by ChangeLens Results Analyzer*
"""
        
        return summary
    
    def save_summary(self, output_file: Optional[str] = None):
        """
        ä¿å­˜æ‘˜è¦åˆ°æ–‡ä»¶
        Save summary to file
        
        Args:
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        """
        if output_file is None:
            output_file = SUMMARY_FILE
        else:
            output_file = Path(output_file)
        
        summary = self.generate_summary()
        
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(summary)
        
        print(f"âœ… æ‘˜è¦å·²ä¿å­˜ / Summary saved: {output_file}")
        return str(output_file)


def main():
    """ä¸»å‡½æ•° / Main function"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ChangeLens ç»“æœåˆ†æå·¥å…· / ChangeLens Results Analyzer')
    parser.add_argument('--data', type=str, default=None, help='æ•°æ®æ–‡ä»¶è·¯å¾„ / Data file path')
    parser.add_argument('--output', type=str, default=None, help='è¾“å‡ºæ‘˜è¦æ–‡ä»¶è·¯å¾„ / Output summary file path')
    
    args = parser.parse_args()
    
    analyzer = ResultsAnalyzer(data_file=args.data)
    
    # æ‰“å°é˜¶æ®µåˆ†æ
    # Print phase analysis
    print("\nğŸ“Š å„é˜¶æ®µæ€§èƒ½æŒ‡æ ‡ / Performance Metrics by Phase:")
    print("-" * 60)
    phases = analyzer.analyze_phases()
    for phase, stats in phases.items():
        print(f"\n{phase}:")
        print(f"  å¹³å‡P99: {stats['avg_p99']:.2f}ms | æœ€å¤§P99: {stats['max_p99']:.2f}ms")
        print(f"  å¹³å‡é”™è¯¯ç‡: {stats['avg_error_rate']:.2f}% | æœ€å¤§é”™è¯¯ç‡: {stats['max_error_rate']:.2f}%")
    
    # å›å½’å½±å“åˆ†æ
    # Regression impact analysis
    print("\nğŸ” å›å½’å½±å“åˆ†æ / Regression Impact Analysis:")
    print("-" * 60)
    regression_impact = analyzer.detect_regression_impact()
    if regression_impact['detected']:
        print(f"P99å¢é•¿: {regression_impact['p99_increase_percent']:.2f}%")
        print(f"é”™è¯¯ç‡å¢é•¿: {regression_impact['error_increase']:.2f}%")
        print(f"å›å½’ä¸¥é‡ç¨‹åº¦: {'ä¸¥é‡' if regression_impact['regression_severe'] else 'ä¸­ç­‰'}")
    else:
        print(regression_impact['message'])
    
    # ç”Ÿæˆå¹¶ä¿å­˜æ‘˜è¦
    # Generate and save summary
    print("\nğŸ“ ç”Ÿæˆæ‘˜è¦ / Generating summary...")
    analyzer.save_summary(output_file=args.output)


if __name__ == "__main__":
    main()
